import requests
from bs4 import BeautifulSoup
import csv

base_url = 'https://www.theverge.com/archives/'
categories = ["tech", "reviews", "science", "entertainment", "features" ]
data = []
year = 2022
month = 1



#while True:
    # for i in range(3):
    #     year += 1
    #     for j in range(12):
    #         month += 1
    #         for k in range(31):
    #             day += 1
    #             url = base_url + str(year) + str(month) + str(day)
    #             response = requests.get(url)
    #             soup = BeautifulSoup(response.content, 'html.parser')
                
    #             # Extract data from the current page
    #             items = soup.find('title')
    #             if items:
    #                 break  # Exit the loop if no more items are found

url = base_url + categories[0] + "/" + str(year) + "/" + "month"
response = requests.get(url)
soup = BeautifulSoup(response.content, 'html.parser')

def has_h2_and_a_with_classes(tag): 
    h2 = tag.find('h2', class_='c-entry-box--compact__title') 
    return h2



# Find all tags that match the filter function
tags_with_h2_and_a = soup.find_all(has_h2_and_a_with_classes(soup))

# Print the results
for tag in tags_with_h2_and_a:
    print(tag.prettify())

    # if not items:
    #     break  # Exit the loop if no more items are found   

    #day += 1
    
    # for item in items:
    #     title = item.find('title').text
    #     data.append([title])




# # Save data to a CSV file
# with open('data.csv', 'w', newline='') as file:
#     writer = csv.writer(file)
#     writer.writerow(['Title'])
#     writer.writerows(data)

print('Data has been saved to data.csv')

    
